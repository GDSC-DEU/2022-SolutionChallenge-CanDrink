{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Please access the http://oasis-deu.xyz:5002/ above and put the downloaded file in the `dataset` folder\n",
    "### 2. `CUDA, cuDNN, nvidia driver` Please check the version\n",
    "### 3. `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 15:21:53.903825: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- chilsung-cider\n",
      "- coca-cola\n",
      "- pepsi\n",
      "- pocari-sweat\n",
      "- sprite\n",
      "- dr-pepper\n",
      "- welchs-grape\n",
      "- powerade\n",
      "- gatorade\n",
      "- monster-energy-ultra\n",
      "nc: 10\n",
      "train: /home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/train.txt\n",
      "val: /home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/val.txt\n"
     ]
    }
   ],
   "source": [
    "%cat dataset/data.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "img_list = glob('dataset/export/images/*')\n",
    "\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1861 466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_img_list, val_img_list = train_test_split(img_list, test_size=0.2, random_state=2000)\n",
    "\n",
    "print(len(train_img_list), len(val_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/train.txt', 'w') as f:\n",
    "  f.write('\\n'.join(train_img_list) + '\\n')\n",
    "\n",
    "with open('dataset/val.txt', 'w') as f:\n",
    "  f.write('\\n'.join(val_img_list) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['chilsung-cider', 'coca-cola', 'pepsi', 'pocari-sweat', 'sprite', 'dr-pepper', 'welchs-grape', 'powerade', 'gatorade', 'monster-energy-ultra'], 'nc': 10, 'train': '/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/train.txt', 'val': '/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/val.txt'}\n",
      "{'names': ['chilsung-cider', 'coca-cola', 'pepsi', 'pocari-sweat', 'sprite', 'dr-pepper', 'welchs-grape', 'powerade', 'gatorade', 'monster-energy-ultra'], 'nc': 10, 'train': '/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/train.txt', 'val': '/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/val.txt'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os \n",
    "\n",
    "with open('dataset/data.yml', 'r') as f:\n",
    "  data = yaml.load(f,Loader=yaml.FullLoader)\n",
    "\n",
    "print(data)\n",
    "\n",
    "data['train'] = f'{os.getcwd()}/dataset/train.txt'\n",
    "data['val'] = f'{os.getcwd()}/dataset/val.txt'\n",
    "\n",
    "with open('dataset/data.yml', 'w') as f:\n",
    "  yaml.dump(data, f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5/models/yolov5s.yaml, data=dataset/data.yml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=8, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=model818, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (offline), for updates see https://github.com/ultralytics/yolov5\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m tensorflow>=1.15.0 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 'pip install tensorflow>=1.15.0' skipped (offline)\n",
      "YOLOv5 üöÄ v6.1-227-ga6e99e4 Python-3.8.10 torch-1.10.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12054MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "2022-06-05 15:22:49.468927: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7046599 parameters, 7046599 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/t\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/dataset/val\u001b[0m\n",
      "Plotting labels to yolov5/runs/train/model8182/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.11 anchors/target, 0.937 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 2 of 1862 labels are < 3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 1861 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8944: 100%|‚ñà‚ñà‚ñà‚ñà\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9989 best possible recall, 8.94 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=1280, metric_all=0.622/0.894-mean/best, past_thr=0.625-mean: 313,610, 397,799, 826,474, 476,949, 633,887, 537,1168, 675,1205, 1189,693, 887,1211\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/model8182\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/49      7.1G   0.07132   0.07353   0.06418        18      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467    0.00727      0.981     0.0538     0.0165\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/49     8.73G    0.0447   0.05894   0.06072        15      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467     0.0134      0.946     0.0838     0.0345\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/49     8.73G   0.04381   0.05167   0.06009        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467    0.00526      0.925     0.0408     0.0135\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/49     8.73G   0.03927   0.04973   0.05965        15      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467     0.0192      0.985      0.101     0.0533\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/49     8.73G   0.03215   0.04755   0.05935        18      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467     0.0785      0.679      0.101     0.0534\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/49     8.73G   0.02913   0.04574   0.05906        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467     0.0866      0.723      0.121     0.0763\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/49     8.73G    0.0265   0.04453   0.05855        18      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.167      0.346      0.156     0.0989\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/49     8.73G   0.02559   0.04312   0.05783        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.191      0.347      0.202      0.129\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/49     8.73G   0.02473    0.0418   0.05673        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.266      0.361      0.241      0.161\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/49     8.73G   0.02384   0.04175   0.05527        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.342      0.446      0.316      0.201\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/49     8.73G   0.02287   0.04116   0.05264        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.327      0.447      0.329      0.231\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/49     8.73G   0.02353   0.03998   0.04991        10      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.364      0.499      0.375      0.237\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/49     8.73G   0.02301   0.04003   0.04562        14      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.419      0.565       0.43      0.289\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/49     8.73G   0.02304   0.03887   0.04357        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.446      0.556      0.483      0.326\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/49     8.73G   0.02254    0.0391   0.04177        16      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.509      0.601      0.532      0.374\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/49     8.73G   0.02214   0.03877   0.03977        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.517      0.657      0.555      0.377\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/49     8.73G   0.02206   0.03736   0.03735        17      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.517      0.623      0.592      0.403\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/49     8.73G   0.02197   0.03793   0.03365        15      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.586      0.703      0.647      0.477\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/49     8.73G   0.02159   0.03785   0.03209        19      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.595      0.674      0.674      0.472\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/49     8.73G   0.02161    0.0371   0.02945        15      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.661      0.746      0.768      0.538\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/49     8.73G   0.02239   0.03721   0.02599        16      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.757      0.706      0.795      0.545\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/49     8.73G    0.0224   0.03712   0.02334        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.656      0.823      0.842      0.594\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/49     8.73G   0.02255   0.03671   0.02037        18      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.721      0.834      0.867      0.598\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/49     8.73G   0.02228   0.03632   0.01735        15      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.732      0.828      0.873      0.599\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/49     8.73G   0.02174    0.0371   0.01572        20      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.757       0.84      0.886      0.608\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/49     8.73G   0.02202   0.03641   0.01422        10      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467       0.75      0.858      0.884      0.607\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/49     8.73G   0.02057   0.03642   0.01274        10      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.761      0.859      0.906       0.63\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/49     8.73G   0.02085   0.03587   0.01167        10      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.788      0.884      0.916      0.649\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/49     8.73G   0.01966   0.03629   0.01085        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.765      0.869      0.902      0.632\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/49     8.73G   0.01957   0.03555   0.01036        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.815      0.849      0.917      0.633\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     30/49     8.73G   0.01928    0.0355   0.01012        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.839      0.878      0.927      0.688\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     31/49     8.73G   0.01828   0.03557   0.00903         9      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.827      0.888      0.924      0.673\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     32/49     8.73G   0.01837   0.03459  0.009123        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.842       0.89      0.933      0.683\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     33/49     8.73G   0.01785   0.03446  0.008343        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.837      0.878      0.925      0.646\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     34/49     8.73G   0.01733   0.03511  0.008315        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.848      0.854      0.924      0.679\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     35/49     8.73G   0.01683    0.0344  0.008342        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.829      0.895      0.929      0.697\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     36/49     8.73G   0.01661   0.03398   0.00668        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.845      0.891      0.937      0.702\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     37/49     8.73G   0.01615   0.03407   0.00643        14      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467       0.84      0.914      0.938      0.708\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     38/49     8.73G   0.01599   0.03399  0.006412        14      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.823      0.871      0.931      0.706\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     39/49     8.73G   0.01544    0.0336  0.005597        14      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.851      0.923      0.939       0.71\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     40/49     8.73G    0.0151   0.03434  0.005455        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.864      0.911      0.947      0.712\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     41/49     8.73G   0.01458   0.03363  0.005243        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.854        0.9       0.94      0.721\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     42/49     8.73G    0.0144   0.03342  0.005091        14      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.837      0.925      0.947      0.706\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     43/49     8.73G   0.01378   0.03314  0.004683        12      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.859      0.906      0.941      0.701\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     44/49     8.73G   0.01366   0.03288  0.004401        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.872       0.92       0.95      0.728\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     45/49     8.73G   0.01323   0.03305  0.004078        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.855      0.942      0.945      0.724\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     46/49     8.73G   0.01274   0.03235  0.003864        10      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.859      0.922      0.948      0.728\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     47/49     8.73G   0.01219   0.03233  0.003673        18      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.854      0.942       0.95      0.735\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     48/49     8.73G   0.01216   0.03218  0.003874        13      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467       0.85      0.928      0.946      0.736\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     49/49     8.73G   0.01171   0.03196  0.003408        11      1280: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.866      0.932      0.949      0.744\n",
      "\n",
      "50 epochs completed in 0.699 hours.\n",
      "Optimizer stripped from yolov5/runs/train/model8182/weights/last.pt, 14.6MB\n",
      "Optimizer stripped from yolov5/runs/train/model8182/weights/best.pt, 14.6MB\n",
      "\n",
      "Validating yolov5/runs/train/model8182/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7037095 parameters, 0 gradients, 15.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        466        467      0.866      0.933      0.949      0.745\n",
      "      chilsung-cider        466         31      0.911      0.993      0.989      0.826\n",
      "           coca-cola        466         29      0.851      0.985      0.918       0.79\n",
      "               pepsi        466         64      0.839      0.897       0.92      0.709\n",
      "        pocari-sweat        466         48      0.718      0.771      0.835      0.505\n",
      "              sprite        466         51      0.877      0.842      0.956      0.695\n",
      "           dr-pepper        466         64      0.901      0.953      0.959       0.76\n",
      "        welchs-grape        466         39      0.923          1       0.99      0.814\n",
      "            powerade        466         45      0.909      0.978      0.979      0.817\n",
      "            gatorade        466         35      0.842      0.912      0.955      0.725\n",
      "monster-energy-ultra        466         61       0.89          1      0.988      0.806\n",
      "Results saved to \u001b[1myolov5/runs/train/model8182\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "!python yolov5/train.py --img 1280 --batch 8 --epochs 50 --data dataset/data.yml --cfg yolov5/models/yolov5s.yaml --weights yolov5s.pt --name model818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=yolov5/data/coco128.yaml, weights=['yolov5/runs/train/model8182/weights/best.pt'], imgsz=[1280], batch_size=1, device=cpu, half=False, inplace=False, train=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\n",
      "YOLOv5 üöÄ v6.1-227-ga6e99e4 Python-3.8.10 torch-1.10.0+cu113 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7037095 parameters, 0 gradients, 15.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5/runs/train/model8182/weights/best.pt with output shape (1, 100800, 15) (13.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.10.0+cu113...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success, saved as yolov5/runs/train/model8182/weights/best.torchscript (27.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.11.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success, saved as yolov5/runs/train/model8182/weights/best.onnx (28.4 MB)\n",
      "\n",
      "Export complete (3.76s)\n",
      "Results saved to \u001b[1m/home/ml/workspace/2022-SolutionChallenge-CanDrink/ml/yolov5/runs/train/model8182/weights\u001b[0m\n",
      "Detect:          python detect.py --weights yolov5/runs/train/model8182/weights/best.onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5/runs/train/model8182/weights/best.onnx')\n",
      "Validate:        python val.py --weights yolov5/runs/train/model8182/weights/best.onnx\n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/export.py --weights yolov5/runs/train/model8182/weights/best.pt --img 1280 --batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 16:09:37.598105: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-05 16:09:37.876429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10101 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: content/output/best9.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: content/output/best9.pb/assets\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"yolov5/runs/train/model8182/weights/best.onnx\")  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "tf_rep.export_graph(\"content/output/best9.pb\")  # export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 69.710 G  ops, equivalently 34.855 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 16:10:29.411953: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-06-05 16:10:29.411977: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-06-05 16:10:29.412453: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: content/output/best9.pb\n",
      "2022-06-05 16:10:29.418887: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-06-05 16:10:29.418913: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: content/output/best9.pb\n",
      "2022-06-05 16:10:29.435585: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-06-05 16:10:29.437719: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-05 16:10:29.525654: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: content/output/best9.pb\n",
      "2022-06-05 16:10:29.580975: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 168523 microseconds.\n",
      "2022-06-05 16:10:29.665912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-06-05 16:10:29.839908: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1972] Estimated count of arithmetic ops: 69.710 G  ops, equivalently 34.855 G  MACs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15768876"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_dir = 'content/output/best9.pb'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "open('converted_model-1280-f16-s.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# saved_model_dir = 'content/output/best5.pb'\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "#                                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# tflite_model = converter.convert()\n",
    "# open('converted_model13.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21b22b7f7c83535e846da71e93ffe8b5f2861c1315ce20daf230f2f2ef843be1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
